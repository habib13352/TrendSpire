<!-- TRENDING_START -->
# ğŸ“ˆ GitHub Trending - Daily

_Last updated: 2025-11-08 12:25 UTC_

| Repository | â­ Stars | Language | Description |
|------------|--------:|----------|-------------|

| [usestrix/strix](https://github.com/usestrix/strix) | 3569 | Python | âœ¨ Open-source AI hackers for your apps ğŸ‘¨ğŸ»â€ğŸ’» |

| [umami-software/umami](https://github.com/umami-software/umami) | 31811 | TypeScript | Umami is a modern, privacy-focused alternative to Google Analytics. |

| [prometheus/alertmanager](https://github.com/prometheus/alertmanager) | 7877 | Go | Prometheus Alertmanager |

| [lima-vm/lima](https://github.com/lima-vm/lima) | 18509 | Go | Linux virtual machines, with a focus on running containers |

| [nocobase/nocobase](https://github.com/nocobase/nocobase) | 18801 | TypeScript | NocoBase is the most extensible AI-powered no-code/low-code platform for building business applications and enterprise solutions. |

| [dbeaver/dbeaver](https://github.com/dbeaver/dbeaver) | 46402 | Java | Free universal database tool and SQL client |

| [localstack/localstack](https://github.com/localstack/localstack) | 62442 | Python | ğŸ’» A fully functional local AWS cloud stack. Develop and test your cloud & Serverless apps offline |

| [Shubhamsaboo/awesome-llm-apps](https://github.com/Shubhamsaboo/awesome-llm-apps) | 75567 | Python | Collection of awesome LLM apps with AI Agents and RAG using OpenAI, Anthropic, Gemini and opensource models. |

| [666ghj/BettaFish](https://github.com/666ghj/BettaFish) | 22530 | Python | å¾®èˆ†ï¼šäººäººå¯ç”¨çš„å¤šAgentèˆ†æƒ…åˆ†æåŠ©æ‰‹ï¼Œæ‰“ç ´ä¿¡æ¯èŒ§æˆ¿ï¼Œè¿˜åŸèˆ†æƒ…åŸè²Œï¼Œé¢„æµ‹æœªæ¥èµ°å‘ï¼Œè¾…åŠ©å†³ç­–ï¼ä»0å®ç°ï¼Œä¸ä¾èµ–ä»»ä½•æ¡†æ¶ã€‚ |

| [airweave-ai/airweave](https://github.com/airweave-ai/airweave) | 4662 | Python | Context retrieval for AI agents across apps and databases |
<!-- TRENDING_END -->

# TrendSpire

TrendSpire gathers trending repositories from GitHub and stores them in `TRENDING.md`. GitHub Actions keep the digest fresh and leverage OpenAI Codex to continuously improve the codebase.

## Features

- Automated scraping of GitHub's trending page with configurable language, time range and result limit.
- Daily workflow to regenerate `TRENDING.md` and update this README.
- Scheduled Codex runs that suggest small refactors and new tests via pull requests.
- Token and cost tracking for all Codex requests.
- Persistent memory stored under `trendspire_memory/` enables the AI to
  iteratively refine its suggestions across runs and open automated pull
  requests with context.

## What TrendSpire Does Today

- `python -m src.fetch_trending` â€” scrape GitHub Trending
- `python -m src.render_digest` â€” render TRENDING.md & inject into README.md

### AI Agents (coming soon)
See [AGENTS.md](./AGENTS.md) and [ai_loop/README.md](./ai_loop/README.md) for details on the self-improvement loop.

## Getting Started

1. **Install dependencies**
   ```bash
   python3 -m venv venv
   source venv/bin/activate
   pip install -r requirements.txt
   ```

2. **Run the setup wizard**
   ```bash
   python scripts/setup_wizard.py
   ```
   This interactive script stores your preferred trending options and OpenAI API key.
   You can rerun it at any time to change the configuration.

3. **Run the trending scraper**
   ```bash
   python -m src.render_digest
   ```
   The latest results will appear in `TRENDING.md` and the README.


## GitHub Actions

### Update Digest

The workflow [`update_digest.yml`](.github/workflows/update_digest.yml) runs every day at 08:00Â UTC. It installs the dependencies, executes `python -m src.render_digest`, and commits any changes to `TRENDING.md` and `README.md`.

### Codex Automation

Another workflow [`ai_loop.yml`](.github/workflows/ai_loop.yml) drives the Codex automation using [`ai_loop/autoloop.py`](ai_loop/autoloop.py). It supports two modes:

- **Daily** â€“ diff-based improvements using `gpt-3.5-turbo`.
- **Weekly** â€“ a full repository review with `gpt-4o`.

Each run applies the returned diff, executes the test suite and, when successful, creates a branch and pull request. Summaries, cost logs and the raw diff are saved under `codex_logs/` and uploaded as workflow artifacts. The workflow also caches the `trendspire_memory/` directory so the AI can refine its suggestions over time.

To run the Codex automation locally you can execute:

```bash
python -m ai_loop.autoloop
```

### API usage reports

The file `logs/api_usage.*` records token counts and cost. Set `API_LOG_FORMAT`
to `csv`, `json` or `txt` to control the format. Run `python
scripts/summarize_usage.py` for a quick summary grouped by model.

### Running tests

After installing the requirements you can run the entire test suite with

```bash
pytest
```

Additional tips for contributors are available in
[docs/DEVELOPER.md](docs/DEVELOPER.md).
---

### ğŸ—ƒ Archived & Legacy Code

This repo includes experimental or deprecated files that are not part of the active AI loop. These are stored in:

- `legacy/` â€“ old logic and patch tools
- `archive/` â€“ past metrics and planning reports
- `later/` â€“ utilities planned for future releases (Phase 5+)
