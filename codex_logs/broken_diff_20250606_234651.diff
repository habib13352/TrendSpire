```diff
diff --git a/src/api_logger.py b/src/api_logger.py
index e69de29..2f8b5f7 100644
--- a/src/api_logger.py
+++ b/src/api_logger.py
@@ -1,4 +1,5 @@
 import csv
+import logging
 import json
 import os
 from datetime import datetime
@@ -11,12 +12,14 @@ USAGE_FILE = os.path.join(LOG_DIR, f"api_usage.{LOG_FORMAT}")
 
 def ensure_log_dir() -> None:
     """Ensure that the log directory and usage file exist."""
+    logging.info("Ensuring log directory and usage file exists.")
     os.makedirs(LOG_DIR, exist_ok=True)
     if not os.path.exists(USAGE_FILE):
         if LOG_FORMAT == "csv":
             with open(USAGE_FILE, "w", encoding="utf-8", newline="") as f:
                 writer = csv.writer(f)
                 writer.writerow([
+                    "timestamp",
                     "service",
                     "model",
                     "prompt_tokens",
@@ -28,17 +31,26 @@ def ensure_log_dir() -> None:
 
 
 def log_openai_usage(model: str, prompt_tokens: int, completion_tokens: int, cost: float) -> None:
+    """Append an OpenAI API usage entry in the selected format."""
+    logging.info("Entering log_openai_usage.")
     ensure_log_dir()
     timestamp = datetime.utcnow().isoformat()
     entry = {
+        "timestamp": timestamp,
         "service": "openai",
         "model": model,
         "prompt_tokens": prompt_tokens,
         "completion_tokens": completion_tokens,
         "cost_usd": float(f"{cost:.6f}"),
     }
+    logging.debug(f"Usage entry to log: {entry}.")
     if LOG_FORMAT == "csv":
         with open(USAGE_FILE, "a", encoding="utf-8", newline="") as f:
             writer = csv.writer(f)
+            logging.info("Logging CSV format usage.")
             writer.writerow(
                 [
                     entry["timestamp"],
@@ -45,16 +57,17 @@ def log_openai_usage(model: str, prompt_tokens: int, completion_tokens: int, cos
                     entry["model"],
                     entry["prompt_tokens"],
                     entry["completion_tokens"],
+                    entry["cost_usd"],
                 ]
             )
     elif LOG_FORMAT == "json":
+        logging.info("Logging JSON format usage.")
         with open(USAGE_FILE, "r+", encoding="utf-8") as f:
             data = json.load(f)
             data.append(entry)
             f.seek(0)
             json.dump(data, f, indent=2)
             f.truncate()
     else:  # txt
+        logging.info("Logging TXT format usage.")
         line = (
             f"{entry['timestamp']} openai {entry['model']} {entry['prompt_tokens']} "
             f"{entry['completion_tokens']} {entry['cost_usd']:.6f}\n"
diff --git a/src/check_ai_quality.py b/src/check_ai_quality.py
index e69de29..d04f5ee 100644
--- a/src/check_ai_quality.py
+++ b/src/check_ai_quality.py
@@ -6,6 +6,7 @@ import os
 from pathlib import Path
 import markdown
 from .utils import log_update
+import logging
 
 REQUIRED_SECTIONS = ["features", "usage", "installation"]
 
@@ -9,6 +43,7 @@ REQUIRED_SECTIONS = ["features", "usage", "installation"]
 def check_readme(readme_path: str | Path = "README.md") -> tuple[bool, str]:
     """Check if README contains all required sections and is valid markdown."""
     content = Path(readme_path).read_text(encoding="utf-8")
+    logging.info(f"Checking README at {readme_path}.")
     try:
         markdown.markdown(content)
     except Exception as exc:
@@ -20,20 +55,26 @@ def main() -> None:
     ok, message = check_readme()
     log_update("readme_quality", message)
+    logging.info(f"README check: {message}")
     if not ok:
         token = os.environ.get("GITHUB_TOKEN")
         repo = os.environ.get("GITHUB_REPOSITORY")
         if token and repo:
             import requests
+            logging.info("GitHub token and repository found, creating issue.")
             url = f"https://api.github.com/repos/{repo}/issues"
             requests.post(url, headers={"Authorization": f"token {token}"}, json={"title": "README quality issue", "body": message})
     print(message)
 
 
 if __name__ == "__main__":
+    logging.info("Starting AI quality check process.")
     main()
diff --git a/src/fetch_trending.py b/src/fetch_trending.py
index e69de29..30128e7 100644
--- a/src/fetch_trending.py
+++ b/src/fetch_trending.py
@@ -9,6 +9,7 @@ from datetime import datetime, timezone
 from pathlib import Path
 from dataclasses import dataclass
 from typing import Any, List
+import logging
 
 from bs4 import BeautifulSoup
 from jinja2 import Environment, FileSystemLoader
@@ -28,9 +29,14 @@ BASE_URL = "https://github.com/trending"
 REQUEST_HEADERS = {"User-Agent": "Mozilla/5.0"}
 TEMPLATE_DIR = Path(__file__).parent / "templates"
 
+logger = logging.getLogger(__name__)
 
 @dataclass
 class Repo:
+    """Container for repository information."""
+    full_name: str
+    url: str
+    description: str
     stars: int
     language: str
 
@@ -43,18 +49,26 @@ FALLBACK_REPO = Repo(
 
 
 def fetch_trending(language: str = "", since: str = "daily", limit: int = 25) -> List[Repo]:
-    """Return a list of trending repositories from GitHub."""
+    """Return a list of trending repositories from GitHub.
+
+    Args:
+        language (str): The programming language to filter trending repositories by.
+        since (str): The time range to consider trending (e.g., 'daily', 'weekly').
+        limit (int): The maximum number of repositories to return.
+
+    Returns:
+        List[Repo]: A list of trending repositories.
+    """
+    logger.info("Fetching trending repositories from GitHub.")
     url = f"{BASE_URL}/{language}" if language else BASE_URL
     params = {"since": since}
     try:
-        resp = fetch_url(url, headers=REQUEST_HEADERS, params=params)
-    except Exception as exc:  # pragma: no cover - network errors
+        resp = fetch_url(url, headers=REQUEST_HEADERS, params=params)
+    except Exception as exc:  # pragma: no cover - network errors
         log_update("fetch_error", str(exc))
         return [FALLBACK_REPO]
 
     soup = BeautifulSoup(resp.text, "html.parser")
     repos: List[Repo] = []
     for item in soup.find_all("article", class_="Box-row")[:limit]:
         repo_path = item.h2.a["href"].strip()
         desc_tag = item.find("p")
@@ -71,6 +85,13 @@ def fetch_trending(language: str = "", since: str = "daily", limit: int = 25) ->
         )
     return repos or [FALLBACK_REPO]
 
+
 def render_markdown(repos: List[Repo], since: str = "daily") -> str:
     """Render trending markdown using the Jinja template."""
+    logger.info("Rendering markdown for trending repositories.")
+    env = Environment(loader=FileSystemLoader(TEMPLATE_DIR))
+    template = env.get_template("trending.j2")
+    return template.render(
+        repos=repos,
+        since=since,
+        timestamp=datetime.now(timezone.utc).strftime("%Y-%m-%d %H:%M UTC"),
+    )
 
diff --git a/src/improve_markdown.py b/src/improve_markdown.py
index 9e10707..673c0b4 100644
--- a/src/improve_markdown.py
+++ b/src/improve_markdown.py
@@ -8,17 +8,20 @@ import difflib
 import os
 from datetime import datetime
 from pathlib import Path
+import logging
 
 from openai import OpenAI, OpenAIError
 
 from .api_logger import log_openai_usage
 
-MODEL = os.getenv("OPENAI_MODEL", "gpt-4o")
+logger = logging.getLogger(__name__)
 
 MODEL = os.getenv("OPENAI_MODEL", "gpt-4o")
 RATE = 0.005 / 1000  # cost per token for gpt-4o
-LOG_DIR = Path("codex_logs")
-COST_LOG = Path("codex_costs.csv")
 
+LOG_DIR = Path("codex_logs")
+COST_LOG = Path("codex_costs.csv")
+
 TRENDING_PROMPT = """You are a GitHub content editor who specializes in trending repositories.\n
 Take the following raw markdown listing of trending GitHub repositories and rewrite it to be:\n
 - Clean and well-formatted\n
@@ -29,37 +32,47 @@ Give only the improved markdown as output."""
 
 README_PROMPT = """You are a GitHub README.md wizard. Take this basic README and improve it by:\n
 - Clearly explaining the project purpose\n
- - Including sections like Features, How it Works, Getting Started, Contributing, and License\n
- - Adding emojis and section headers for readability\n
- - Making it appealing to developers and content creators\n\n
+ - Including sections like Features, How it Works, Getting Started, Contributing, and License\n
+ - Adding emojis and section headers for readability\n
+ - Making it appealing to developers and content creators\n\n
 Here is the original README:\n---\n{content}\n---\n\nReturn only the improved markdown."""
 
 
 def ensure_logs() -> None:
     """Ensure log directories and cost file exist."""
+    logger.info("Ensuring log directories and cost file exist.")
     LOG_DIR.mkdir(exist_ok=True)
     if not COST_LOG.exists():
         with COST_LOG.open("w", encoding="utf-8") as f:
             f.write(
                 "timestamp,run_type,prompt_tokens,completion_tokens,model,cost_usd\n"
             )
 
+
 def append_cost(run_type: str, tokens: tuple[int, int], model: str, cost: float) -> None:
     """Append the cost of an OpenAI API call to the cost log."""
+    logger.info(f"Appending cost: type={run_type}, model={model}, cost={cost:.6f}")
     timestamp = datetime.utcnow().strftime("%Y%m%d_%H%M%S")
     with COST_LOG.open("a", encoding="utf-8") as f:
         f.write(
             f"{timestamp},{run_type},{tokens[0]},{tokens[1]},{model},{cost:.6f}\n"
         )
 
+
 def call_openai(prompt: str) -> tuple[str, tuple[int, int]]:
     """Invoke the OpenAI API to process a prompt and return the improved markdown and token count."""
+    logger.info("Calling OpenAI API with prompt.")
     client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))
     response = client.chat.completions.create(
         model=MODEL,
         messages=[{"role": "user", "content": prompt}],
     )
     usage = response.usage
     tokens = (usage.prompt_tokens, usage.completion_tokens)
     cost = (tokens[0] + tokens[1]) * RATE
+    logger.debug(f"OpenAI API response tokens: {tokens}, cost: {cost:.6f}")
     log_openai_usage(MODEL, tokens[0], tokens[1], cost)
     append_cost("improve", tokens, MODEL, cost)
     return response.choices[0].message.content.strip(), tokens
 
+
 def write_diff(old: str, new: str, name: str) -> None:
+    """Write a unified diff between old and new content if they differ meaningfully."""
     if old == new:
         return
@@ -71,12 +84,16 @@ def write_diff(old: str, new: str, name: str) -> None:
     diff_path.write_text("\n".join(diff), encoding="utf-8")
 
+
 def improve_trending(path: Path) -> bool:
     """Improve the markdown file at the given path using OpenAI."""
+    logger.info(f"Improving trending markdown at {path}.")
     original = path.read_text(encoding="utf-8")
     prompt = TRENDING_PROMPT.format(content=original)
     try:
+        logger.info("Calling OpenAI for trending improvement.")
         improved, _tokens = call_openai(prompt)
     except OpenAIError as exc:
         logger.error(f"OpenAI call failed: {exc}")
         print(exc)
@@ -85,6 +102,7 @@ def improve_trending(path: Path) -> bool:
     if improved and improved != original:
         path.write_text(improved + "\n", encoding="utf-8")
         write_diff(original, improved, "trending")
+        logger.info("Trending markdown improved and saved.")
         return True
     return False
 
@@ -91,6 +109,7 @@ def improve_readme(path: Path) -> bool:
     """Improve the README file format using OpenAI."""
+    logger.info(f"Improving README at {path}.")
     content = path.read_text(encoding="utf-8")
     start = "<!-- TRENDING_START -->"
     end = "<!-- TRENDING_END -->"
@@ -104,6 +123,7 @@ def improve_readme(path: Path) -> bool:
     try:
+        logger.info("Calling OpenAI for README improvement.")
         improved, _tokens = call_openai(prompt)
     except OpenAIError as exc:
         logger.error(f"OpenAI call failed: {exc}")
@@ -112,6 +132,7 @@ def improve_readme(path: Path) -> bool:
     if new_content != content:
         path.write_text(new_content, encoding="utf-8")
         write_diff(content, new_content, "readme")
+        logger.info("README improved and saved.")
         return True
     return False
 
@@ -119,17 +140,19 @@ def main() -> None:
     """Main function to improve markdown files using OpenAI."""
+    logger.info("Starting markdown improvement process.")
     ensure_logs()
     changed = False
     trending_path = Path("TRENDING.md")
     if trending_path.exists():
         changed |= improve_trending(trending_path)
     readme_path = Path("README.md")
     if readme_path.exists():
         changed |= improve_readme(readme_path)
     if not changed:
         print("No improvements made.")
+        logger.info("No improvements made.")
 
 
 if __name__ == "__main__":
-    main()
+    main()
diff --git a/tests/test_api_logger.py b/tests/test_api_logger.py
new file mode 100644
index 0000000..d62f172
--- /dev/null
+++ b/tests/test_api_logger.py
@@ -0,0 +1,52 @@
+import os
+import json
+import csv
+import pytest
+from src.api_logger import ensure_log_dir, log_openai_usage, LOG_FORMAT, USAGE_FILE
+
+
+@pytest.fixture
+def setup_log():
+    # Set up for tests
+    ensure_log_dir()
+    yield
+    # Clean up after tests
+    if os.path.exists(USAGE_FILE):
+        os.remove(USAGE_FILE)
+
+
+def test_ensure_log_dir_csv_creation(setup_log):
+    if LOG_FORMAT == "csv":
+        assert os.path.exists(USAGE_FILE)
+        with open(USAGE_FILE, "r", encoding="utf-8") as f:
+            reader = csv.reader(f)
+            headers = next(reader)
+            assert headers == [
+                "timestamp",
+                "service",
+                "model",
+                "prompt_tokens",
+                "completion_tokens",
+                "cost_usd",
+            ]
+
+
+def test_log_openai_usage_csv(setup_log):
+    if LOG_FORMAT == "csv":
+        model = "gpt-3.5-turbo"
+        prompt_tokens = 100
+        completion_tokens = 150
+        cost = 0.05
+        log_openai_usage(model, prompt_tokens, completion_tokens, cost)
+        
+        with open(USAGE_FILE, "r", encoding="utf-8") as f:
+            reader = csv.reader(f)
+            _headers = next(reader)
+            row = next(reader)
+            assert row[1] == "openai"
+            assert row[2] == model
+            assert int(row[3]) == prompt_tokens
+            assert int(row[4]) == completion_tokens
+            assert float(row[5]) == cost
```